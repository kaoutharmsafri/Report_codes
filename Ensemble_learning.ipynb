{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ccbfb54",
   "metadata": {},
   "source": [
    "# Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c23922",
   "metadata": {},
   "source": [
    "## Automatic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "081d0bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-2.0.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost) (1.10.1)\n",
      "Using cached xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f8e9aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error, mean_squared_log_error, median_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, auc,precision_score,recall_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier,StackingClassifier , BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91ff096c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1003 entries, 0 to 1002\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Gender          1003 non-null   int64  \n",
      " 1   Experience      1003 non-null   float64\n",
      " 2   Niveau          1003 non-null   float64\n",
      " 3   Weighted_Score  1003 non-null   float64\n",
      " 4   Output          1003 non-null   int64  \n",
      " 5   Domain          1003 non-null   int64  \n",
      "dtypes: float64(3), int64(3)\n",
      "memory usage: 47.1 KB\n",
      "None\n",
      "\n",
      "X:\n",
      "   Gender  Experience  Niveau  Domain\n",
      "0       1        0.24    0.42       6\n",
      "1       0        0.03    0.25       9\n",
      "2       1        0.10    0.17       8\n",
      "3       1        0.24    0.42       2\n",
      "4       1        0.07    0.42       3\n",
      "\n",
      "y:\n",
      "\n",
      "X shape : (1003, 4)\n",
      "y shape : (1003,)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('clean_data_60_40.csv')\n",
    "print(data.info())\n",
    "\n",
    "df=data\n",
    "\n",
    "\n",
    "X = df.drop(['Output', 'Weighted_Score'], axis=1)\n",
    "y = df['Output']\n",
    "\n",
    "print(\"\\nX:\")\n",
    "print(X[:5])\n",
    "print(\"\\ny:\")\n",
    "# print(y[:50])\n",
    "print('\\nX shape :',X.shape)\n",
    "print('y shape :',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af296c61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Stacking Classifier\n",
      "\n",
      " *** Testing Performance:\n",
      "Accuracy: 0.9950\n",
      "Auc: 0.9945\n",
      "Roc: 0.9945\n",
      "f1_score: [0.99547511 0.99447514]\n",
      "f1_score mean: 0.9950\n",
      "precision_score: [0.99099099 1.        ]\n",
      "precision_score mean: 0.9955\n",
      "recall_score: [1.         0.98901099]\n",
      "recall_score mean: 0.9945\n",
      "Gini Coefficient: 0.9890\n",
      "\n",
      "confusion_matrix: [[110   0]\n",
      " [  1  90]]\n",
      "--------------------\n",
      "\n",
      " *** Detailed Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       110\n",
      "           1       1.00      0.99      0.99        91\n",
      "\n",
      "    accuracy                           1.00       201\n",
      "   macro avg       1.00      0.99      0.99       201\n",
      "weighted avg       1.00      1.00      1.00       201\n",
      "\n",
      "Model: Bagging Classifier\n",
      "\n",
      " *** Testing Performance:\n",
      "Accuracy: 0.9950\n",
      "Auc: 0.9945\n",
      "Roc: 0.9945\n",
      "f1_score: [0.99547511 0.99447514]\n",
      "f1_score mean: 0.9950\n",
      "precision_score: [0.99099099 1.        ]\n",
      "precision_score mean: 0.9955\n",
      "recall_score: [1.         0.98901099]\n",
      "recall_score mean: 0.9945\n",
      "Gini Coefficient: 0.9890\n",
      "\n",
      "confusion_matrix: [[110   0]\n",
      " [  1  90]]\n",
      "--------------------\n",
      "\n",
      " *** Detailed Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       110\n",
      "           1       1.00      0.99      0.99        91\n",
      "\n",
      "    accuracy                           1.00       201\n",
      "   macro avg       1.00      0.99      0.99       201\n",
      "weighted avg       1.00      1.00      1.00       201\n",
      "\n",
      "Model: AdaBoost\n",
      "\n",
      " *** Testing Performance:\n",
      "Accuracy: 0.9950\n",
      "Auc: 0.9945\n",
      "Roc: 0.9945\n",
      "f1_score: [0.99547511 0.99447514]\n",
      "f1_score mean: 0.9950\n",
      "precision_score: [0.99099099 1.        ]\n",
      "precision_score mean: 0.9955\n",
      "recall_score: [1.         0.98901099]\n",
      "recall_score mean: 0.9945\n",
      "Gini Coefficient: 0.9890\n",
      "\n",
      "confusion_matrix: [[110   0]\n",
      " [  1  90]]\n",
      "--------------------\n",
      "\n",
      " *** Detailed Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       110\n",
      "           1       1.00      0.99      0.99        91\n",
      "\n",
      "    accuracy                           1.00       201\n",
      "   macro avg       1.00      0.99      0.99       201\n",
      "weighted avg       1.00      1.00      1.00       201\n",
      "\n",
      "Model: Gradient Boosting\n",
      "\n",
      " *** Testing Performance:\n",
      "Accuracy: 0.9950\n",
      "Auc: 0.9945\n",
      "Roc: 0.9945\n",
      "f1_score: [0.99547511 0.99447514]\n",
      "f1_score mean: 0.9950\n",
      "precision_score: [0.99099099 1.        ]\n",
      "precision_score mean: 0.9955\n",
      "recall_score: [1.         0.98901099]\n",
      "recall_score mean: 0.9945\n",
      "Gini Coefficient: 0.9890\n",
      "\n",
      "confusion_matrix: [[110   0]\n",
      " [  1  90]]\n",
      "--------------------\n",
      "\n",
      " *** Detailed Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       110\n",
      "           1       1.00      0.99      0.99        91\n",
      "\n",
      "    accuracy                           1.00       201\n",
      "   macro avg       1.00      0.99      0.99       201\n",
      "weighted avg       1.00      1.00      1.00       201\n",
      "\n",
      "Model: Random Forest\n",
      "\n",
      " *** Testing Performance:\n",
      "Accuracy: 0.9950\n",
      "Auc: 0.9945\n",
      "Roc: 0.9945\n",
      "f1_score: [0.99547511 0.99447514]\n",
      "f1_score mean: 0.9950\n",
      "precision_score: [0.99099099 1.        ]\n",
      "precision_score mean: 0.9955\n",
      "recall_score: [1.         0.98901099]\n",
      "recall_score mean: 0.9945\n",
      "Gini Coefficient: 0.9890\n",
      "\n",
      "confusion_matrix: [[110   0]\n",
      " [  1  90]]\n",
      "--------------------\n",
      "\n",
      " *** Detailed Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       110\n",
      "           1       1.00      0.99      0.99        91\n",
      "\n",
      "    accuracy                           1.00       201\n",
      "   macro avg       1.00      0.99      0.99       201\n",
      "weighted avg       1.00      1.00      1.00       201\n",
      "\n",
      "Model: XG Boosting\n",
      "\n",
      " *** Testing Performance:\n",
      "Accuracy: 0.9950\n",
      "Auc: 0.9945\n",
      "Roc: 0.9945\n",
      "f1_score: [0.99547511 0.99447514]\n",
      "f1_score mean: 0.9950\n",
      "precision_score: [0.99099099 1.        ]\n",
      "precision_score mean: 0.9955\n",
      "recall_score: [1.         0.98901099]\n",
      "recall_score mean: 0.9945\n",
      "Gini Coefficient: 0.9890\n",
      "\n",
      "confusion_matrix: [[110   0]\n",
      " [  1  90]]\n",
      "--------------------\n",
      "\n",
      " *** Detailed Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       110\n",
      "           1       1.00      0.99      0.99        91\n",
      "\n",
      "    accuracy                           1.00       201\n",
      "   macro avg       1.00      0.99      0.99       201\n",
      "weighted avg       1.00      1.00      1.00       201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = []\n",
    "models.append(('Logistic Regression', LogisticRegression()))\n",
    "models.append(('Linear Discriminant Analysis(LDA)', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(probability=True)))\n",
    "models.append(('Decision Tree', DecisionTreeClassifier()))\n",
    "\n",
    "model_names = []\n",
    "accuracy_score_test_values = []\n",
    "auc_test_values = []\n",
    "roc_auc_test_values = []\n",
    "f1_score_test_values = []\n",
    "precision_test_values = []\n",
    "recall_test_values = []\n",
    "confusion_matrix_test_values = []\n",
    "gini_coefficient_values = []\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "# Define ensemble models\n",
    "stacking_clf = StackingClassifier(estimators=models)\n",
    "bagging_clf = BaggingClassifier()\n",
    "adaboost_clf = AdaBoostClassifier()\n",
    "gradientboost_clf = GradientBoostingClassifier()\n",
    "randomforest_clf = RandomForestClassifier()\n",
    "xgboost_clf = XGBClassifier()\n",
    "\n",
    "# Train ensemble models\n",
    "ensemble_models = [\n",
    "    ('Stacking Classifier', stacking_clf),\n",
    "    ('Bagging Classifier', bagging_clf),\n",
    "    ('AdaBoost', adaboost_clf),\n",
    "    ('Gradient Boosting', gradientboost_clf),\n",
    "    ('Random Forest', randomforest_clf),    \n",
    "    ('XG Boosting', xgboost_clf),\n",
    "]\n",
    "\n",
    "for name, ensemble_model in ensemble_models:\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "    y_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "    # Evaluate performance on testing  set\n",
    "    accuracy_score_test=accuracy_score(y_test, y_pred, normalize=True)\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    auc_test=metrics.auc(fpr, tpr)\n",
    "    \n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    confusion_matrix_test=confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    f1_score_test=f1_score(y_test, y_pred, average=None)\n",
    "    \n",
    "    gini_coefficient = 2 * roc_auc_test - 1\n",
    "    \n",
    "    precision_test = precision_score(y_test, y_pred, average=None)\n",
    "\n",
    "    recall_test = recall_score(y_test, y_pred, average=None)\n",
    "\n",
    "    # Add results to their corresponding arrays\n",
    "    model_names.append(name)\n",
    "    accuracy_score_test_values.append(accuracy_score_test)\n",
    "    auc_test_values.append(auc_test)\n",
    "    roc_auc_test_values.append(roc_auc_test)\n",
    "    f1_score_test_values.append(f1_score_test)\n",
    "    confusion_matrix_test_values.append(confusion_matrix_test)\n",
    "    gini_coefficient_values.append(gini_coefficient)\n",
    "    precision_test_values.append(precision_test)\n",
    "    recall_test_values.append(recall_test)\n",
    "    \n",
    "    # Display the results\n",
    "    print(f'Model: {name}')\n",
    "    print(\"\\n *** Testing Performance:\")\n",
    "    print(f'Accuracy: {accuracy_score_test:.4f}')\n",
    "    print(f'Auc: {auc_test:.4f}')\n",
    "    print(f'Roc: {roc_auc_test:.4f}')\n",
    "    print(f'f1_score: {f1_score_test}')\n",
    "    print(f'f1_score mean: {f1_score_test.mean():.4f}')\n",
    "    print(f'precision_score: {precision_test}')\n",
    "    print(f'precision_score mean: {precision_test.mean():.4f}')\n",
    "    print(f'recall_score: {recall_test}')\n",
    "    print(f'recall_score mean: {recall_test.mean():.4f}')\n",
    "    print(f'Gini Coefficient: {gini_coefficient:.4f}')\n",
    "    print(f'\\nconfusion_matrix: {confusion_matrix_test}')\n",
    "    print('-' * 20)\n",
    "    \n",
    "    print(\"\\n *** Detailed Performance:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36377f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Stacking Classifier\n",
      "Mean Accuracy with cross validation: 0.99900\n",
      "\n",
      "Model: Bagging Classifier\n",
      "Mean Accuracy with cross validation: 0.99700\n",
      "\n",
      "Model: AdaBoost\n",
      "Mean Accuracy with cross validation: 0.99700\n",
      "\n",
      "Model: Gradient Boosting\n",
      "Mean Accuracy with cross validation: 0.99701\n",
      "\n",
      "Model: Random Forest\n",
      "Mean Accuracy with cross validation: 0.99401\n",
      "\n",
      "Model: XG Boosting\n",
      "Mean Accuracy with cross validation: 0.99600\n"
     ]
    }
   ],
   "source": [
    "for name, model in ensemble_models:\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    cv_results_auc = model_selection.cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "    \n",
    "    # Display the results\n",
    "    print(f'\\nModel: {name}')\n",
    "    print(f\"Mean Accuracy with cross validation: {cv_results_auc.mean():.5f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275cf3",
   "metadata": {},
   "source": [
    "## Tuning hyperparamets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efb81514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning hyperparameters for Stacking Classifier...\n",
      "Best parameters found:\n",
      "{'stack_method': 'auto'}\n",
      "Best cross-validation accuracy: 1.0000\n",
      "\n",
      "Tuning hyperparameters for Bagging Classifier...\n",
      "Best parameters found:\n",
      "{'max_samples': 1.0, 'n_estimators': 10}\n",
      "Best cross-validation accuracy: 1.0000\n",
      "\n",
      "Tuning hyperparameters for AdaBoost...\n",
      "Best parameters found:\n",
      "{'learning_rate': 1.0, 'n_estimators': 50}\n",
      "Best cross-validation accuracy: 1.0000\n",
      "\n",
      "Tuning hyperparameters for Gradient Boosting...\n",
      "Best parameters found:\n",
      "{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100}\n",
      "Best cross-validation accuracy: 1.0000\n",
      "\n",
      "Tuning hyperparameters for Random Forest...\n",
      "Best parameters found:\n",
      "{'max_depth': None, 'n_estimators': 200}\n",
      "Best cross-validation accuracy: 0.9988\n",
      "\n",
      "Tuning hyperparameters for XG Boosting...\n",
      "Best parameters found:\n",
      "{'learning_rate': 1.0, 'max_depth': 3, 'n_estimators': 50}\n",
      "Best cross-validation accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grids for each ensemble model\n",
    "ensemble_param_grid = {\n",
    "    'Stacking Classifier': {\n",
    "        'stack_method': ['auto', 'predict_proba'],\n",
    "    },\n",
    "    'Bagging Classifier': {\n",
    "        'n_estimators': [10, 50, 100],\n",
    "        'max_samples': [0.5, 1.0],\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 1.0],\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 1.0],\n",
    "        'max_depth': [3, 5, 7],\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 5, 10],\n",
    "    },\n",
    "    'XG Boosting': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 1.0],\n",
    "        'max_depth': [3, 5, 7],\n",
    "    }\n",
    "}\n",
    "best_estimators = {}\n",
    "\n",
    "# Loop over ensemble models and perform parameter tuning\n",
    "for name, model in ensemble_models:\n",
    "    if name in ensemble_param_grid:\n",
    "        print(f\"\\nTuning hyperparameters for {name}...\")\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=ensemble_param_grid[name], cv=5, scoring='accuracy')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_estimators[name] = grid_search.best_estimator_\n",
    "        print(\"Best parameters found:\")\n",
    "        print(grid_search.best_params_)\n",
    "        print(\"Best cross-validation accuracy: {:.4f}\".format(grid_search.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c1434f",
   "metadata": {},
   "source": [
    "## Tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1c943c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04811c34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Stacking Classifier\n",
      "\n",
      " *** Testing Performance:\n",
      "Accuracy: 0.9950\n",
      "Auc: 0.9945\n",
      "Roc: 0.9945\n",
      "f1_score: [0.99547511 0.99447514]\n",
      "f1_score mean: 0.9950\n",
      "precision_score: [0.99099099 1.        ]\n",
      "precision_score mean: 0.9955\n",
      "recall_score: [1.         0.98901099]\n",
      "recall_score mean: 0.9945\n",
      "Gini Coefficient: 0.9890\n",
      "\n",
      "confusion_matrix: [[110   0]\n",
      " [  1  90]]\n",
      "--------------------\n",
      "\n",
      " *** Detailed Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       110\n",
      "           1       1.00      0.99      0.99        91\n",
      "\n",
      "    accuracy                           1.00       201\n",
      "   macro avg       1.00      0.99      0.99       201\n",
      "weighted avg       1.00      1.00      1.00       201\n",
      "\n",
      "Model: Bagging Classifier\n",
      "\n",
      " *** Testing Performance:\n",
      "Accuracy: 0.9950\n",
      "Auc: 0.9945\n",
      "Roc: 0.9945\n",
      "f1_score: [0.99547511 0.99447514]\n",
      "f1_score mean: 0.9950\n",
      "precision_score: [0.99099099 1.        ]\n",
      "precision_score mean: 0.9955\n",
      "recall_score: [1.         0.98901099]\n",
      "recall_score mean: 0.9945\n",
      "Gini Coefficient: 0.9890\n",
      "\n",
      "confusion_matrix: [[110   0]\n",
      " [  1  90]]\n",
      "--------------------\n",
      "\n",
      " *** Detailed Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       110\n",
      "           1       1.00      0.99      0.99        91\n",
      "\n",
      "    accuracy                           1.00       201\n",
      "   macro avg       1.00      0.99      0.99       201\n",
      "weighted avg       1.00      1.00      1.00       201\n",
      "\n",
      "Model: AdaBoost\n",
      "\n",
      " *** Testing Performance:\n",
      "Accuracy: 0.9950\n",
      "Auc: 0.9945\n",
      "Roc: 0.9945\n",
      "f1_score: [0.99547511 0.99447514]\n",
      "f1_score mean: 0.9950\n",
      "precision_score: [0.99099099 1.        ]\n",
      "precision_score mean: 0.9955\n",
      "recall_score: [1.         0.98901099]\n",
      "recall_score mean: 0.9945\n",
      "Gini Coefficient: 0.9890\n",
      "\n",
      "confusion_matrix: [[110   0]\n",
      " [  1  90]]\n",
      "--------------------\n",
      "\n",
      " *** Detailed Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       110\n",
      "           1       1.00      0.99      0.99        91\n",
      "\n",
      "    accuracy                           1.00       201\n",
      "   macro avg       1.00      0.99      0.99       201\n",
      "weighted avg       1.00      1.00      1.00       201\n",
      "\n",
      "Model: Gradient Boosting\n",
      "\n",
      " *** Testing Performance:\n",
      "Accuracy: 0.9950\n",
      "Auc: 0.9945\n",
      "Roc: 0.9945\n",
      "f1_score: [0.99547511 0.99447514]\n",
      "f1_score mean: 0.9950\n",
      "precision_score: [0.99099099 1.        ]\n",
      "precision_score mean: 0.9955\n",
      "recall_score: [1.         0.98901099]\n",
      "recall_score mean: 0.9945\n",
      "Gini Coefficient: 0.9890\n",
      "\n",
      "confusion_matrix: [[110   0]\n",
      " [  1  90]]\n",
      "--------------------\n",
      "\n",
      " *** Detailed Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       110\n",
      "           1       1.00      0.99      0.99        91\n",
      "\n",
      "    accuracy                           1.00       201\n",
      "   macro avg       1.00      0.99      0.99       201\n",
      "weighted avg       1.00      1.00      1.00       201\n",
      "\n",
      "Model: Random Forest\n",
      "\n",
      " *** Testing Performance:\n",
      "Accuracy: 0.9950\n",
      "Auc: 0.9945\n",
      "Roc: 0.9945\n",
      "f1_score: [0.99547511 0.99447514]\n",
      "f1_score mean: 0.9950\n",
      "precision_score: [0.99099099 1.        ]\n",
      "precision_score mean: 0.9955\n",
      "recall_score: [1.         0.98901099]\n",
      "recall_score mean: 0.9945\n",
      "Gini Coefficient: 0.9890\n",
      "\n",
      "confusion_matrix: [[110   0]\n",
      " [  1  90]]\n",
      "--------------------\n",
      "\n",
      " *** Detailed Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       110\n",
      "           1       1.00      0.99      0.99        91\n",
      "\n",
      "    accuracy                           1.00       201\n",
      "   macro avg       1.00      0.99      0.99       201\n",
      "weighted avg       1.00      1.00      1.00       201\n",
      "\n",
      "Model: XG Boosting\n",
      "\n",
      " *** Testing Performance:\n",
      "Accuracy: 0.9950\n",
      "Auc: 0.9945\n",
      "Roc: 0.9945\n",
      "f1_score: [0.99547511 0.99447514]\n",
      "f1_score mean: 0.9950\n",
      "precision_score: [0.99099099 1.        ]\n",
      "precision_score mean: 0.9955\n",
      "recall_score: [1.         0.98901099]\n",
      "recall_score mean: 0.9945\n",
      "Gini Coefficient: 0.9890\n",
      "\n",
      "confusion_matrix: [[110   0]\n",
      " [  1  90]]\n",
      "--------------------\n",
      "\n",
      " *** Detailed Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       110\n",
      "           1       1.00      0.99      0.99        91\n",
      "\n",
      "    accuracy                           1.00       201\n",
      "   macro avg       1.00      0.99      0.99       201\n",
      "weighted avg       1.00      1.00      1.00       201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Define ensemble models\n",
    "stacking_clf = StackingClassifier(estimators=models,stack_method='auto')\n",
    "bagging_clf = BaggingClassifier(max_samples=1.0,n_estimators=10)\n",
    "adaboost_clf = AdaBoostClassifier(learning_rate=1.0,n_estimators=50)\n",
    "gradientboost_clf = GradientBoostingClassifier(learning_rate=0.01,max_depth=5,n_estimators=100)\n",
    "randomforest_clf = RandomForestClassifier(max_depth=10,n_estimators=200)\n",
    "xgboost_clf = XGBClassifier(learning_rate=1.0,max_depth=3,n_estimators=50)\n",
    "# Train ensemble models\n",
    "ensemble_models = [\n",
    "    ('Stacking Classifier', stacking_clf),\n",
    "    ('Bagging Classifier', bagging_clf),\n",
    "    ('AdaBoost', adaboost_clf),\n",
    "    ('Gradient Boosting', gradientboost_clf),\n",
    "    ('Random Forest', randomforest_clf),    \n",
    "    ('XG Boosting', xgboost_clf),\n",
    "]\n",
    "\n",
    "for name, ensemble_model in ensemble_models:\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "    y_pred = ensemble_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate performance on testing  set\n",
    "    accuracy_score_test=accuracy_score(y_test, y_pred, normalize=True)\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    auc_test=metrics.auc(fpr, tpr)\n",
    "    \n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    confusion_matrix_test=confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    f1_score_test=f1_score(y_test, y_pred, average=None)\n",
    "    \n",
    "    gini_coefficient = 2 * roc_auc_test - 1\n",
    "    \n",
    "    precision_test = precision_score(y_test, y_pred, average=None)\n",
    "\n",
    "    recall_test = recall_score(y_test, y_pred, average=None)\n",
    "\n",
    "    # Add results to their corresponding arrays\n",
    "    model_names.append(name)\n",
    "    accuracy_score_test_values.append(accuracy_score_test)\n",
    "    auc_test_values.append(auc_test)\n",
    "    roc_auc_test_values.append(roc_auc_test)\n",
    "    f1_score_test_values.append(f1_score_test)\n",
    "    confusion_matrix_test_values.append(confusion_matrix_test)\n",
    "    gini_coefficient_values.append(gini_coefficient)\n",
    "    precision_test_values.append(precision_test)\n",
    "    recall_test_values.append(recall_test)\n",
    "    \n",
    "    # Display the results\n",
    "    print(f'Model: {name}')\n",
    "    print(\"\\n *** Testing Performance:\")\n",
    "    print(f'Accuracy: {accuracy_score_test:.4f}')\n",
    "    print(f'Auc: {auc_test:.4f}')\n",
    "    print(f'Roc: {roc_auc_test:.4f}')\n",
    "    print(f'f1_score: {f1_score_test}')\n",
    "    print(f'f1_score mean: {f1_score_test.mean():.4f}')\n",
    "    print(f'precision_score: {precision_test}')\n",
    "    print(f'precision_score mean: {precision_test.mean():.4f}')\n",
    "    print(f'recall_score: {recall_test}')\n",
    "    print(f'recall_score mean: {recall_test.mean():.4f}')\n",
    "    print(f'Gini Coefficient: {gini_coefficient:.4f}')\n",
    "    print(f'\\nconfusion_matrix: {confusion_matrix_test}')\n",
    "    print('-' * 20)\n",
    "    \n",
    "    print(\"\\n *** Detailed Performance:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0c81111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Stacking Classifier\n",
      "Mean Accuracy with cross validation: 0.99800\n",
      "\n",
      "Model: Bagging Classifier\n",
      "Mean Accuracy with cross validation: 0.99900\n",
      "\n",
      "Model: AdaBoost\n",
      "Mean Accuracy with cross validation: 0.99700\n",
      "\n",
      "Model: Gradient Boosting\n",
      "Mean Accuracy with cross validation: 0.99900\n",
      "\n",
      "Model: Random Forest\n",
      "Mean Accuracy with cross validation: 0.99201\n",
      "\n",
      "Model: XG Boosting\n",
      "Mean Accuracy with cross validation: 0.99600\n"
     ]
    }
   ],
   "source": [
    "for name, model in ensemble_models:\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    cv_results_auc = model_selection.cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "    \n",
    "    # Display the results\n",
    "    print(f'\\nModel: {name}')\n",
    "    print(f\"Mean Accuracy with cross validation: {cv_results_auc.mean():.5f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b123d5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6441541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
